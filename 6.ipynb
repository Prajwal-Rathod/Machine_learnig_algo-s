{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajat\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample instances from the dataset are given below\n",
      "   age  gender  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0   63       1   1       145   233    1        2      150      0      2.3   \n",
      "1   67       1   4       160   286    0        2      108      1      1.5   \n",
      "2   67       1   4       120   229    0        2      129      1      2.6   \n",
      "3   37       1   3       130   250    0        0      187      0      3.5   \n",
      "4   41       0   2       130   204    0        2      172      0      1.4   \n",
      "\n",
      "   slope   ca  thal  heartdisease  \n",
      "0      3  0.0   6.0             0  \n",
      "1      2  3.0   3.0             2  \n",
      "2      2  2.0   7.0             1  \n",
      "3      3  0.0   3.0             0  \n",
      "4      1  0.0   3.0             0  \n",
      "\n",
      "Attributes and datatypes\n",
      "age               int64\n",
      "gender            int64\n",
      "cp                int64\n",
      "trestbps          int64\n",
      "chol              int64\n",
      "fbs               int64\n",
      "restecg           int64\n",
      "thalach           int64\n",
      "exang             int64\n",
      "oldpeak         float64\n",
      "slope             int64\n",
      "ca              float64\n",
      "thal            float64\n",
      "heartdisease      int64\n",
      "dtype: object\n",
      "\n",
      "Learning CPD using Maximum likelihood estimators\n",
      "\n",
      "Inferencing with Bayesian Network:\n",
      "\n",
      "1. Probability of HeartDisease given evidence= restecg\n",
      "+-----------------+---------------------+\n",
      "| heartdisease    |   phi(heartdisease) |\n",
      "+=================+=====================+\n",
      "| heartdisease(0) |              0.1012 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(1) |              0.0000 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(2) |              0.2392 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(3) |              0.2015 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(4) |              0.4581 |\n",
      "+-----------------+---------------------+\n",
      "\n",
      "2. Probability of HeartDisease given evidence= cp\n",
      "+-----------------+---------------------+\n",
      "| heartdisease    |   phi(heartdisease) |\n",
      "+=================+=====================+\n",
      "| heartdisease(0) |              0.3610 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(1) |              0.2159 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(2) |              0.1373 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(3) |              0.1537 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(4) |              0.1321 |\n",
      "+-----------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "# Load and preprocess dataset\n",
    "heartDisease = pd.read_csv('Medical Dataset.csv').replace('?', np.nan)\n",
    "heartDisease[['ca', 'thal']] = heartDisease[['ca', 'thal']].apply(pd.to_numeric, errors='coerce')\n",
    "heartDisease.dropna(inplace=True)\n",
    "\n",
    "# Display sample instances and datatypes\n",
    "print('Sample instances from the dataset are given below')\n",
    "print(heartDisease.head())\n",
    "print('\\nAttributes and datatypes')\n",
    "print(heartDisease.dtypes)\n",
    "\n",
    "# Define the Bayesian Network structure and learn CPD using Maximum Likelihood Estimation\n",
    "model = BayesianNetwork([('age', 'heartdisease'), ('gender', 'heartdisease'), ('exang', 'heartdisease'),\n",
    "                         ('cp', 'heartdisease'), ('heartdisease', 'restecg'), ('heartdisease', 'chol')])\n",
    "print('\\nLearning CPD using Maximum likelihood estimators')\n",
    "model.fit(heartDisease, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Inference with Bayesian Network\n",
    "print('\\nInferencing with Bayesian Network:')\n",
    "HeartDiseasetest = VariableElimination(model)\n",
    "\n",
    "# Queries\n",
    "print('\\n1. Probability of HeartDisease given evidence= restecg')\n",
    "print(HeartDiseasetest.query(variables=['heartdisease'], evidence={'restecg': 1}))\n",
    "print('\\n2. Probability of HeartDisease given evidence= cp')\n",
    "print(HeartDiseasetest.query(variables=['heartdisease'], evidence={'cp': 2}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"Feature1\": [1, 4, 7, 10, 13, 16, 19, 22, 25, 28],\n",
    "    \"Feature2\": [2, 5, 8, 11, 14, 17, 20, 23, 26, 29],\n",
    "    \"Feature3\": [3, 6, 9, 12, 15, 18, 21, 24, 27, 30],\n",
    "    \"Target\": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(\"4ds.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from CSV:\n",
      "    Feature1  Feature2  Feature3  Target\n",
      "0         1         2         3       0\n",
      "1         4         5         6       1\n",
      "2         7         8         9       0\n",
      "3        10        11        12       1\n",
      "4        13        14        15       0\n",
      "Data after preprocessing:\n",
      "    Feature1  Feature2  Feature3  Target\n",
      "0         1         2         3       0\n",
      "1         4         5         6       1\n",
      "2         7         8         9       0\n",
      "3        10        11        12       1\n",
      "4        13        14        15       0\n",
      "X_train:\n",
      "    Feature1  Feature2  Feature3\n",
      "0         1         2         3\n",
      "7        22        23        24\n",
      "2         7         8         9\n",
      "9        28        29        30\n",
      "4        13        14        15\n",
      "y_train:\n",
      " 0    0\n",
      "7    1\n",
      "2    0\n",
      "9    1\n",
      "4    0\n",
      "Name: Target, dtype: int64\n",
      "X_train after scaling:\n",
      " [[-1.54230764 -1.54230764 -1.54230764]\n",
      " [ 0.89553347  0.89553347  0.89553347]\n",
      " [-0.84578161 -0.84578161 -0.84578161]\n",
      " [ 1.5920595   1.5920595   1.5920595 ]\n",
      " [-0.14925558 -0.14925558 -0.14925558]]\n",
      "X_test after scaling:\n",
      " [[ 1.24379649  1.24379649  1.24379649]\n",
      " [-1.19404463 -1.19404463 -1.19404463]\n",
      " [ 0.19900744  0.19900744  0.19900744]]\n",
      "Predictions: [1 0 0]\n",
      "Actual: [0 1 1]\n",
      "Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sagar\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def read_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data read from CSV:\\n\", data.head())\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    le = LabelEncoder()\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == object:\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "    print(\"Data after preprocessing:\\n\", data.head())\n",
    "    return data\n",
    "\n",
    "def build_ann(data):\n",
    "    data = preprocess_data(data)\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    print(\"X_train:\\n\", X_train.head())\n",
    "    print(\"y_train:\\n\", y_train.head())\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"X_train after scaling:\\n\", X_train[:5])\n",
    "    print(\"X_test after scaling:\\n\", X_test[:5])\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    predictions = mlp.predict(X_test)\n",
    "    \n",
    "    print(\"Predictions:\", predictions)\n",
    "    print(\"Actual:\", y_test.values)\n",
    "    \n",
    "    return accuracy_score(y_test, predictions)\n",
    "\n",
    "# Example usage:\n",
    "data = read_csv('4ds.csv')\n",
    "accuracy = build_ann(data)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
